{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cea41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAANYAAL\\AppData\\Local\\Temp\\ipykernel_2748\\3005889099.py:16: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  arima_data = df[['date', 'wind']].set_index('date').resample('1H').mean().ffill()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ARIMA model with (p=2, d=1, q=2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DAANYAAL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\DAANYAAL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ARIMA model saved to models/arima_model.pkl\n",
      "Training LSTM model...\n",
      "Epoch 1/10\n",
      "595/595 [==============================] - 16s 23ms/step - loss: 0.0173\n",
      "Epoch 2/10\n",
      "595/595 [==============================] - 14s 23ms/step - loss: 0.0147\n",
      "Epoch 3/10\n",
      "595/595 [==============================] - 14s 23ms/step - loss: 0.0144\n",
      "Epoch 4/10\n",
      "595/595 [==============================] - 14s 24ms/step - loss: 0.0140\n",
      "Epoch 5/10\n",
      "595/595 [==============================] - 15s 25ms/step - loss: 0.0135\n",
      "Epoch 6/10\n",
      "595/595 [==============================] - 14s 24ms/step - loss: 0.0132\n",
      "Epoch 7/10\n",
      "595/595 [==============================] - 14s 24ms/step - loss: 0.0128\n",
      "Epoch 8/10\n",
      "595/595 [==============================] - 14s 24ms/step - loss: 0.0124\n",
      "Epoch 9/10\n",
      "595/595 [==============================] - 14s 24ms/step - loss: 0.0120\n",
      "Epoch 10/10\n",
      "595/595 [==============================] - 15s 24ms/step - loss: 0.0117\n",
      "✅ LSTM model saved to models/lstm_model.h5\n",
      "✅ Scaler saved to models/lstm_scaler.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DAANYAAL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from model_utils import load_config, load_storm_data, save_arima_model, save_lstm_model\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to train and save models based on configuration settings.\n",
    "    Handles both ARIMA and LSTM models.\n",
    "    \"\"\"\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Create necessary directories\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load configuration\n",
    "    try:\n",
    "        with open(\"config2.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Config file not found. Creating default config.\")\n",
    "        config = {\n",
    "            \"model\": \"arima\",\n",
    "            \"arima\": {\"p\": 2, \"d\": 1, \"q\": 2, \"use\": True},\n",
    "            \"lstm\": {\"epochs\": 10, \"batch_size\": 32, \"sequence_length\": 10, \"use\": False}\n",
    "        }\n",
    "        with open(\"config2.json\", \"w\") as f:\n",
    "            json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Get model choice from config\n",
    "    model_choice = config.get(\"model\", \"arima\").lower()\n",
    "    print(f\"Selected model: {model_choice}\")\n",
    "    \n",
    "    # Load training data\n",
    "    try:\n",
    "        print(\"Loading training data...\")\n",
    "        train_data = load_storm_data(\"data/storms.csv\")\n",
    "        print(f\"Loaded {len(train_data)} records\")\n",
    "        \n",
    "        # Check if data is valid\n",
    "        if train_data is None or len(train_data) < 10:\n",
    "            print(\"Warning: Not enough training data. Using default data.\")\n",
    "            # Generate default data\n",
    "            dates = pd.date_range(start='2023-01-01', periods=60)\n",
    "            np.random.seed(42)\n",
    "            wind_speeds = 50 + 15 * np.sin(np.arange(60) * 0.1) + np.random.normal(0, 5, 60)\n",
    "            train_data = pd.DataFrame({\n",
    "                'date': dates,\n",
    "                'wind_speed': wind_speeds\n",
    "            })\n",
    "            # Save default data\n",
    "            train_data.to_csv(\"data/storms.csv\", index=False)\n",
    "            print(\"Created default training data\")\n",
    "    \n",
    "        # Ensure data is sorted by date and reset index\n",
    "        train_data = train_data.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        # Fill any missing values in wind_speed\n",
    "        train_data['wind_speed'] = train_data['wind_speed'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "        # Train appropriate model based on configuration\n",
    "        results_csv = os.path.join(\"models\", \"forecast_results.csv\")\n",
    "        results_png = os.path.join(\"models\", \"forecast_plot.png\")\n",
    "        \n",
    "        if model_choice == \"arima\":\n",
    "            train_arima(train_data, config, results_csv, results_png)\n",
    "        elif model_choice == \"lstm\":\n",
    "            train_lstm(train_data, config, results_csv, results_png)\n",
    "        else:\n",
    "            print(f\"Unknown model type: {model_choice}\")\n",
    "            return\n",
    "        \n",
    "        print(\"Model training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def train_arima(train_data, config, results_csv, results_png):\n",
    "    \"\"\"Train ARIMA model and save results\"\"\"\n",
    "    print(\"Training ARIMA model...\")\n",
    "    \n",
    "    # Get ARIMA parameters from config\n",
    "    p = config['arima'].get('p', 2)\n",
    "    d = config['arima'].get('d', 1)\n",
    "    q = config['arima'].get('q', 2)\n",
    "    \n",
    "    # Validate parameters\n",
    "    p = max(0, min(5, p))  # Limit p between 0 and 5\n",
    "    d = max(0, min(2, d))  # Limit d between 0 and 2\n",
    "    q = max(0, min(5, q))  # Limit q between 0 and 5\n",
    "    \n",
    "    print(f\"ARIMA parameters: p={p}, d={d}, q={q}\")\n",
    "    \n",
    "    # Get wind speed values\n",
    "    values = train_data[\"wind_speed\"].values\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(values) < 5:\n",
    "        raise ValueError(\"Not enough data for ARIMA model. Need at least 5 rows.\")\n",
    "    \n",
    "    # Create and fit ARIMA model\n",
    "    model = ARIMA(values, order=(p, d, q))\n",
    "    model_fit = model.fit()\n",
    "    print(\"ARIMA model fitted successfully\")\n",
    "    \n",
    "    # Generate forecast\n",
    "    forecast_steps = min(10, len(values))  # forecast up to 10 steps or less if data is small\n",
    "    forecast = model_fit.forecast(steps=forecast_steps)\n",
    "    print(f\"Forecasted wind speed for next {forecast_steps} steps: {forecast}\")\n",
    "    \n",
    "    # Save model\n",
    "    save_arima_model(model_fit, os.path.join(\"models\", \"arima_model.pkl\"))\n",
    "    print(\"ARIMA model saved\")\n",
    "    \n",
    "    # Prepare results DataFrame\n",
    "    last_date = pd.to_datetime(train_data['date'].iloc[-1])\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_steps)\n",
    "    results_df = pd.DataFrame({\"date\": future_dates, \"forecasted_wind_speed\": forecast})\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    print(f\"Results saved to {results_csv}\")\n",
    "    \n",
    "    # Plot and save results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_data['date'], train_data[\"wind_speed\"], label=\"Historical Wind Speed\")\n",
    "    plt.plot(results_df[\"date\"], results_df[\"forecasted_wind_speed\"], label=\"Forecast\", marker=\"o\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Wind Speed\")\n",
    "    plt.title(f\"Wind Speed Forecast - ARIMA({p},{d},{q})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_png)\n",
    "    plt.close()\n",
    "    print(f\"Forecast plot saved to {results_png}\")\n",
    "\n",
    "def train_lstm(train_data, config, results_csv, results_png):\n",
    "    \"\"\"Train LSTM model and save results\"\"\"\n",
    "    print(\"Training LSTM model...\")\n",
    "    \n",
    "    # Get LSTM parameters from config\n",
    "    epochs = config['lstm'].get('epochs', 10)\n",
    "    batch_size = config['lstm'].get('batch_size', 32)\n",
    "    sequence_length = config['lstm'].get('sequence_length', 10)\n",
    "    \n",
    "    # Validate parameters\n",
    "    epochs = max(1, min(100, epochs))  # Limit epochs between 1 and 100\n",
    "    batch_size = max(1, min(128, batch_size))  # Limit batch_size between 1 and 128\n",
    "    sequence_length = max(1, min(20, sequence_length))  # Limit sequence_length between 1 and 20\n",
    "    \n",
    "    print(f\"LSTM parameters: epochs={epochs}, batch_size={batch_size}, sequence_length={sequence_length}\")\n",
    "    \n",
    "    # Prepare data for LSTM\n",
    "    values = train_data[\"wind_speed\"].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(scaled_values) <= sequence_length:\n",
    "        raise ValueError(f\"Not enough data for LSTM. Need more than sequence_length={sequence_length} rows.\")\n",
    "    \n",
    "    # Create sequences for LSTM\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(scaled_values)):\n",
    "        X.append(scaled_values[i-sequence_length:i, 0])\n",
    "        y.append(scaled_values[i, 0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    # Create and train LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "        LSTM(units=50),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    print(\"LSTM model compiled, starting training...\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2)\n",
    "    print(\"LSTM model trained successfully\")\n",
    "    \n",
    "    # Save model and scaler\n",
    "    save_lstm_model(model, scaler, \n",
    "                    os.path.join(\"models\", \"lstm_model.h5\"), \n",
    "                    os.path.join(\"models\", \"lstm_scaler.pkl\"))\n",
    "    print(\"LSTM model and scaler saved\")\n",
    "    \n",
    "    # Generate forecasts\n",
    "    history_sequence = list(scaled_values[-sequence_length:].flatten())\n",
    "    predictions = []\n",
    "    forecast_steps = min(10, len(scaled_values))\n",
    "    \n",
    "    for _ in range(forecast_steps):\n",
    "        X_input = np.array(history_sequence[-sequence_length:]).reshape(1, sequence_length, 1)\n",
    "        pred = model.predict(X_input, verbose=0)\n",
    "        predictions.append(pred[0][0])\n",
    "        history_sequence.append(pred[0][0])\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    predicted_values = scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Prepare results DataFrame\n",
    "    last_date = pd.to_datetime(train_data['date'].iloc[-1])\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_steps)\n",
    "    results_df = pd.DataFrame({\"date\": future_dates, \"forecasted_wind_speed\": predicted_values})\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    print(f\"Results saved to {results_csv}\")\n",
    "    \n",
    "    # Plot and save results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_data['date'], train_data[\"wind_speed\"], label=\"Historical Wind Speed\")\n",
    "    plt.plot(results_df[\"date\"], results_df[\"forecasted_wind_speed\"], label=\"Forecast\", marker=\"o\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Wind Speed\")\n",
    "    plt.title(\"Wind Speed Forecast - LSTM\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_png)\n",
    "    plt.close()\n",
    "    print(f\"Forecast plot saved to {results_png}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254647b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
