%%%%%%%%%%%%%%%%%%%%%%%%
%
% $Autor: Daanyaal Parvaize, Keerti Belmane, Kreetika Mohanta $
% $Datum: 2025-06-11 20:48:02Z $
% $Pfad: D:/BA_PROJECT/BA25-02-Time-Series/report//Contents/en/Important Modules.tex$
% $Version: 4621 $
%
% !TeX encoding = utf8
% !TeX root = Rename
%
%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Important Modules}

All required Python modules for this project can be freely downloaded and installed from the official Python Package Index (PyPI) \cite{pythonpypi}.


\section{Pandas}
\subsection{Pandas Overview}
The \texttt{pandas} library is a cornerstone of Python-based data science, delivering powerful, intuitive, and high-performance tools for analyzing and manipulating structured datasets \cite{mckinney2011pandas}. Tailored for efficiency, it provides flexible data structures that streamline complex data operations, making it indispensable for tasks like preprocessing time-series wind speed data in \texttt{model\_utils.py} and formatting forecast outputs in \texttt{app.py}. Its expressive design empowers users to handle meteorological data with ease, aligning with the project's goal of generating accurate hurricane intensity predictions. By offering a robust framework for data wrangling, \texttt{pandas} ensures seamless integration into the data pipeline, from ingestion to analysis.

\subsection{Pandas Functionality}
Central to \texttt{pandas} are its \texttt{Series} and \texttt{DataFrame} structures, which facilitate efficient manipulation of labeled, tabular data, offering functionality comparable to R and SQL environments \cite{mckinney2011pandas}. The \texttt{DataFrame}, a two-dimensional table, supports operations such as sorting, filtering, and missing value imputation, as utilized in \texttt{model\_utils.py} to clean wind speed datasets. The \texttt{Series}, a one-dimensional array with labeled indices, enables precise time-series handling, critical for ARIMA and LSTM inputs in \texttt{train\_models.ipynb}. These structures allow for intuitive data operations, such as chronological sorting of timestamps and coercion of non-numeric values, ensuring data integrity. In the project, \texttt{pandas} underpins the preprocessing pipeline, enabling robust data preparation and output generation in \texttt{app.py}, enhancing the reliability of hurricane forecasts.
\subsection{Installing Pandas}
This guide helps you install the pandas library, a fantastic tool for working with data in Python. If you're brand new to coding, don't worry—we'll go step by step to get pandas up and running on your computer. You'll need Python installed, and we'll use a tool called pip to download pandas. Let's jump in and make it happen!

First, check if Python is installed on your computer. Open a terminal—on Windows, this could be Command Prompt or PowerShell; on Mac or Linux, use the Terminal app. Type \texttt{python --version} and press Enter. If you see a version number, like Python 3.8 or higher, you're all set. If you get an error, head to \url{https://www.python.org/downloads/}, download the latest Python version, and follow the installation steps. During setup, make sure to check the option to add Python to your system PATH so you can run it from the terminal easily.

Next, confirm that pip, Python's package installer, is ready to go. In the terminal, type \texttt{pip --version} and press Enter. If a version number pops up, pip is good to use. If not, you’ll need to install pip. Visit \texttt{https://bootstrap.pypa.io/get-pip.py}, download the \texttt{get-pip.py} file, save it to your computer, and then run \texttt{python get-pip.py} in the terminal from the folder where you saved the file. This sets up pip, letting you install libraries like pandas.

Now it’s time to install pandas! In your terminal, type this command and press Enter:
\begin{verbatim}
	pip install pandas
\end{verbatim}
This tells pip to fetch pandas and any extra bits it needs, like another library called numpy. You’ll see some text scrolling by as it downloads and installs. When it’s done, pandas is ready to use on your computer.

To make sure pandas installed correctly, open a Python session by typing \texttt{python} in the terminal and pressing Enter. Then type \texttt{import pandas as pd} and press Enter. If nothing goes wrong (no error messages), pandas is working! Try typing \texttt{pd.Series([1, 2, 3])} and press Enter to see a small list of numbers displayed as a pandas Series, a cool way to store data. When you’re done, type \texttt{exit()} and press Enter to close Python.

If something doesn’t work, check your internet connection, as pip needs it to download pandas. You can also try updating pip by typing \texttt{pip install --upgrade pip} and pressing Enter, then retry the installation. If you’re still stuck, make sure you’re using a recent Python version, like 3.8 or later, since pandas works best with those. Once pandas is installed, you’re ready to explore data in Python.

\subsection{Example: Using Pandas}
This subsection demonstrates how to utilize the \texttt{pandas} library to load data from a comma-separated values (CSV) file into a \texttt{DataFrame} and perform essential operations such as filtering and aggregation. These operations are critical for analyzing structured datasets, enabling users to extract valuable insights. The examples are designed for beginners, offering step-by-step Python code with explanations. For clarity, the code uses \texttt{readcsv} as a simplified representation of the \texttt{pandas} \texttt{read\_csv} method and avoids underscores in variable names. The examples assume \texttt{pandas} is installed and use a sample CSV file with columns for product names, prices, and quantities.

Consider a CSV file named \texttt{datafile.csv} with the following content:
\begin{verbatim}
	product,price,quantity
	Laptop,999.99,5
	Phone,499.99,10
	Tablet,299.99,8
\end{verbatim}
The first example illustrates loading this file into a \texttt{DataFrame} using \texttt{pandas}.

\begin{lstlisting}[style=pythonstyle,caption={Loading a CSV file into a DataFrame},label={lst:pandas_load}]
	import pandas as pd
	
	# Load the CSV file into a DataFrame
	df = pd.readcsv('datafile.csv')
	
	# Display the DataFrame
	print(df)
\end{lstlisting}
This code imports \texttt{pandas} with the alias \texttt{pd}, loads \texttt{datafile.csv} into a \texttt{DataFrame} named \texttt{df}, and prints its contents. The output displays a table with columns \texttt{product}, \texttt{price}, and \texttt{quantity}, mirroring the CSV structure. The \texttt{readcsv} method (representing \texttt{read\_csv}) interprets the first row as column headers, simplifying data access.

The second example shows filtering the \texttt{DataFrame} to select rows where the price exceeds 400. Filtering allows users to focus on specific data subsets based on conditions.

\begin{lstlisting}[style=pythonstyle,caption={Filtering rows in a DataFrame},label={lst:pandas_filter}]
	import pandas as pd
	
	# Load the CSV file
	df = pd.readcsv('datafile.csv')
	
	# Filter rows where price is greater than 400
	expensiveproducts = df[df['price'] > 400]
	
	# Display the filtered DataFrame
	print(expensiveproducts)
\end{lstlisting}
The condition \texttt{df['price'] > 400} creates a boolean mask, and \texttt{df[...]} selects matching rows. The resulting \texttt{DataFrame}, \texttt{expensiveproducts}, includes only rows for \texttt{Laptop} and \texttt{Phone}, with prices of 999.99 and 499.99, respectively. This technique is useful for isolating relevant data points, such as high-value items.

The third example performs aggregation, calculating the average price and total quantity across all products. Aggregation summarizes data, providing insights into overall trends.

\begin{lstlisting}[style=pythonstyle,caption={Aggregating data in a DataFrame},label={lst:pandas_aggregate}]
	import pandas as pd
	
	# Load the CSV file
	df = pd.readcsv('datafile.csv')
	
	# Compute the average price and total quantity
	averageprice = df['price'].mean()
	totalquantity = df['quantity'].sum()
	
	# Display the results
	print(f"Average Price: ${averageprice:.2f}")
	print(f"Total Quantity: {totalquantity}")
\end{lstlisting}
The \texttt{mean} method calculates the average of the \texttt{price} column (599.99), and the \texttt{sum} method totals the \texttt{quantity} column (23). The results are formatted for clarity using string formatting. These operations enable users to derive summary statistics, essential for understanding dataset characteristics.

These examples provide beginners with foundational skills to load, filter, and aggregate data using \texttt{pandas}. Users can extend these techniques to handle larger datasets or perform more complex analyses, advancing their data science proficiency.

\subsection{Example -- Manual}
\begin{verbatim}
	import pandas as pd
	df = pd.DataFrame({'a':[1,2,3], 'b':[4,5,6]})
	df = df[df['a'] > 1]
\end{verbatim}
\subsection{Example -- Code}
\begin{lstlisting}[style=pythonstyle,caption={Grouping and aggregating data},label={lst:pandas_group}]
	import pandas as pd
	
	# Create a DataFrame from a dictionary
	data = pd.DataFrame({'category': ['A', 'B', 'A', 'B'], 'value': [10, 20, 30, 40]})
	
	# Group by category and sum the value column
	groupsum = data.groupby('category').agg({'value': 'sum'})
	
	# Display the grouped DataFrame
	print(groupsum)
\end{lstlisting}

\subsection{Example -- Files}
Loading and saving data in various formats:
\begin{verbatim}
	# CSV
	df.to_csv('out.csv', index=False)
	df = pd.read_csv('out.csv')
	
	# Excel
	df.to_excel('out.xlsx', sheet_name='Sheet1', index=False)
	df = pd.read_excel('in.xlsx', sheet_name='Sheet1')
	
	# JSON
	df.to_json('data.json', orient='records', lines=True)
	df = pd.read_json('data.json', lines=True)
	
	# Pickle (for saving/loading Python objects)
	df.to_pickle('data.pkl')
	df = pd.read_pickle('data.pkl')
	
	# SQL (using sqlite3 as an example)
	import sqlite3
	conn = sqlite3.connect('example.db')
	df.to_sql('table_name', conn, if_exists='replace', index=False)
	df = pd.read_sql('SELECT * FROM table_name', conn)
\end{verbatim}


\subsection{Further Reading}
Wes McKinney, \textit{pandas: a Foundational Python Library for Data Analysis and Statistics} \cite{mckinney2011pandas}.

\section{Statsmodels}

\subsection{Introduction}
Statsmodels is an open-source Python library designed for econometric and statistical modeling, hypothesis testing, and data exploration \cite{seabold2010statsmodels}. It complements the scientific Python ecosystem by providing classes and functions to estimate many different statistical models, perform statistical tests, and conduct data exploration and visualization. Statsmodels is widely used in academic research and industry for its robustness, comprehensive statistical output, and R-like interface, making it particularly valuable for users with backgrounds in statistics and econometrics.

\subsection{Description}
Statsmodels provides extensive capabilities in the following areas:

\begin{itemize}
	\item \textbf{Regression Models:} Supports a broad spectrum of regression techniques including Ordinary Least Squares (OLS), Generalized Least Squares (GLS), Weighted Least Squares (WLS), robust regression methods, and Generalized Linear Models (GLM) such as logistic and Poisson regression.
	\item \textbf{Time-Series Analysis:} Implements classic time-series models such as Autoregressive Integrated Moving Average (ARIMA), Seasonal ARIMA (SARIMA), Vector Autoregression (VAR), state space models, and structural time series.
	\item \textbf{Statistical Tests and Diagnostics:} Includes tools for hypothesis testing (e.g., t-tests, F-tests), diagnostic tests for autocorrelation (Durbin-Watson), heteroscedasticity (Breusch-Pagan), normality (Jarque-Bera), and multicollinearity, among others.
	\item \textbf{Model Evaluation and Inference:} Detailed summaries of model fits are provided including coefficient estimates, standard errors, confidence intervals, p-values, goodness-of-fit statistics (R-squared, AIC, BIC), and residual analysis.
	\item \textbf{Formula Interface:} Similar to R’s formula syntax, allowing users to specify models in a concise and readable way using strings.
	\item \textbf{Integration:} Seamlessly integrates with pandas DataFrames for data handling, and with NumPy and SciPy for numerical and scientific computation.
\end{itemize}

\subsection{Installation}
Installing Statsmodels is straightforward but, as a new user, here are some step-by-step tips to make sure everything goes smoothly:

\begin{enumerate}
	\item \textbf{Install Python:}  
	Make sure you have Python installed on your computer. You can download it from \url{https://www.python.org/downloads/}. For most users, Python 3.8 or higher is recommended.
	
	\item \textbf{Set up a Virtual Environment (Recommended):}  
	It’s good practice to create an isolated environment for your projects to avoid conflicts between different Python packages.
	
	\begin{verbatim}
		python -m venv myenv
	\end{verbatim}
	
	This creates a new environment named \texttt{myenv}. Activate it with:
	\begin{itemize}
		\item On Windows:
		\begin{verbatim}
			myenv\Scripts\activate
		\end{verbatim}
		\item On macOS/Linux:
		\begin{verbatim}
			source myenv/bin/activate
		\end{verbatim}
	\end{itemize}
	
	\item \textbf{Upgrade pip:}  
	Before installing, upgrade pip (Python’s package manager) to the latest version:
	\begin{verbatim}
		pip install --upgrade pip
	\end{verbatim}
	
	\item \textbf{Install Statsmodels:}  
	Now you can install Statsmodels using pip:
	\begin{verbatim}
		pip install statsmodels
	\end{verbatim}
	This command will also install the required dependencies like \texttt{numpy}, \texttt{scipy}, and \texttt{pandas} if you don't have them already.
	
	\item \textbf{Verify Installation:}  
	After installation, check if Statsmodels is correctly installed by running Python and importing it:
	\begin{verbatim}
		python
		>>> import statsmodels.api as sm
		>>> print(sm.__version__)
	\end{verbatim}
	If no errors appear and the version number prints, you are ready to go!
	
	\item \textbf{Optional - Using Anaconda:}  
	If you are using the Anaconda Python distribution, Statsmodels can be installed via conda:
	\begin{verbatim}
		conda install statsmodels
	\end{verbatim}
	This is often easier for beginners as it handles all dependencies automatically.
\end{enumerate}

By following these steps, even if you are new to Python and package installation, you will be able to set up Statsmodels and start your statistical modeling smoothly.


\subsection{Example -- Description}
Statsmodels shines in providing comprehensive statistical analysis with rich diagnostic information, unlike many machine learning libraries focused primarily on prediction accuracy. Its typical workflow includes:

\begin{enumerate}
	\item Specifying a model either through matrices (endogenous and exogenous variables) or via formula strings.
	\item Fitting the model to data, estimating parameters using maximum likelihood or least squares.
	\item Examining detailed output reports to interpret coefficients, test hypotheses, and diagnose model adequacy.
	\item Using fitted models for prediction, forecasting, and simulation.
\end{enumerate}

Common modeling scenarios include:

\begin{itemize}
	\item \textbf{Linear Regression:} Understand the relationship between a dependent variable and one or more independent variables.
	\item \textbf{Time-Series Forecasting:} Model and forecast data collected over time, accounting for trends, seasonality, and autocorrelation.
	\item \textbf{Categorical Outcome Modeling:} Logistic regression for binary or multinomial outcomes.
\end{itemize}

\subsection{Example -- Manual}
Here are some fundamental examples illustrating Statsmodels usage on a dataset \texttt{df} containing variables \texttt{a}, \texttt{b}, \texttt{c}, and a binary \texttt{outcome}:

\begin{verbatim}
	# Example 1: Linear regression using OLS (matrix interface)
	import statsmodels.api as sm
	X = sm.add_constant(df[['a']])  # Adds intercept term
	model = sm.OLS(df['b'], X).fit()
	print(model.summary())
	
	# Example 2: Time-Series ARIMA model
	from statsmodels.tsa.arima.model import ARIMA
	model = ARIMA(df['b'], order=(1,1,1))
	fit = model.fit()
	print(fit.summary())
	
	# Example 3: Logistic regression with formula API
	import statsmodels.formula.api as smf
	logit_model = smf.logit('outcome ~ a + c', data=df).fit()
	print(logit_model.summary())
\end{verbatim}

Each of these examples demonstrates how Statsmodels provides detailed statistical summaries including parameter estimates, confidence intervals, and diagnostic statistics.

\subsection{Example -- Code}
More advanced examples combining model fitting, prediction, and diagnostic testing:

\begin{verbatim}
	# Example 1: Linear regression with formula and prediction
	import statsmodels.formula.api as smf
	fit = smf.ols('b ~ a + c', data=df).fit()
	print(fit.summary())
	predictions = fit.predict(df[['a', 'c']])
	
	# Example 2: Seasonal ARIMA for forecasting
	from statsmodels.tsa.statespace.sarimax import SARIMAX
	model = SARIMAX(df['b'], order=(1,1,1), seasonal_order=(1,1,1,12))
	results = model.fit()
	forecast = results.get_forecast(steps=5)
	print(forecast.summary_frame())
	
	# Example 3: Conducting heteroscedasticity test on residuals
	from statsmodels.stats.diagnostic import het_breuschpagan
	lm_test = het_breuschpagan(fit.resid, fit.model.exog)
	print('Breusch-Pagan test statistic:', lm_test[0])
	print('p-value:', lm_test[1])
\end{verbatim}

These examples highlight the versatility of Statsmodels, ranging from predictive modeling to rigorous statistical diagnostics.

\subsection{Example -- Files}
Statsmodels natively supports working with pandas DataFrames, facilitating smooth data handling. For persistent storage, models can be saved and reloaded using Python’s serialization libraries such as \texttt{pickle} or \texttt{joblib}, enabling workflows that require saving fitted models for future predictions or sharing.

Example of saving and loading a fitted model:

\begin{lstlisting}[language=python, basicstyle=\ttfamily\small]
	import pickle
	
	# Save model to disk
	with open('linear_model.pkl', 'wb') as f:
	pickle.dump(fit, f)
	
	# Load model from disk
	with open('linear_model.pkl', 'rb') as f:
	loaded_model = pickle.load(f)
	
	# Use loaded model to predict new data
	new_predictions = loaded_model.predict(new_df[['a', 'c']])
\end{lstlisting}


Additionally, Statsmodels supports exporting results to tables compatible with LaTeX or HTML for easy reporting.

\subsection{Further Reading}
Seabold, S., \& Perktold, J. (2010). \textit{Statsmodels: Econometric and Statistical Modeling with Python}. Proceedings of the 9th Python in Science Conference \cite{seabold2010statsmodels} provides a detailed overview and motivation behind Statsmodels' development and capabilities.



\section{TensorFlow}

\subsection{Introduction}
TensorFlow is an open-source framework developed by Google for large-scale machine learning and deep learning applications. It allows users to design, train, and deploy machine learning models using flexible and efficient dataflow graphs \cite{abadi2016tensorflow}. TensorFlow supports both research experimentation and production deployment, enabling models to run on a variety of hardware, from personal devices to distributed clusters.

\subsection{Description}
TensorFlow's core strength lies in its ability to represent complex computations as dataflow graphs where nodes correspond to mathematical operations, and edges represent multidimensional data arrays called tensors. It provides extensive support for:

\begin{itemize}
	\item \textbf{Distributed Computing:} TensorFlow can automatically distribute computation across CPUs, GPUs, and specialized hardware like TPUs (Tensor Processing Units), optimizing performance for large datasets and complex models.
	\item \textbf{Deep Neural Networks:} Includes high-level APIs such as \texttt{tf.keras} to build and train deep learning models with layers like convolutional, recurrent, and dense layers.
	\item \textbf{Eager Execution:} TensorFlow 2.x enables dynamic computation, allowing immediate evaluation of operations, which simplifies debugging and accelerates model development.
	\item \textbf{Data Pipelines:} Tools like \texttt{tf.data} provide efficient input pipelines to preprocess and feed data for training.
	\item \textbf{Model Deployment:} Facilities to save, export, and deploy models across platforms including mobile, web, and cloud services.
\end{itemize}

\subsection{Installation}
To install TensorFlow, follow these step-by-step instructions designed especially for users new to Python and machine learning:

\begin{enumerate}
	\item \textbf{Prerequisites:}  
	Make sure you have Python 3.7 or later installed on your computer. You can download it from \url{https://www.python.org/downloads/}.  
	To confirm your Python version, open your command prompt (Windows) or terminal (Linux/macOS) and run:
	\begin{verbatim}
		python --version
	\end{verbatim}
	
	\item \textbf{Set Up a Virtual Environment (Recommended):}  
	It is a good practice to create a virtual environment to keep your Python packages organized and prevent conflicts:
	\begin{verbatim}
		python -m venv tensorflow-env
	\end{verbatim}
	Activate it by running:
	
	\begin{itemize}
		\item Windows:
		\begin{framed}
		\begin{verbatim}
			
			tensorflow-env\Scripts\activate
			
		\end{verbatim}
	\end{framed}
		\item macOS/Linux:
		\begin{framed}
		\begin{verbatim}
			
			source tensorflow-env/bin/activate
		
		\end{verbatim}
	\end{framed}
	\end{itemize}
	
	\item \textbf{Install TensorFlow via pip:}  
	With your virtual environment activated, run:
	\begin{framed}
	\begin{verbatim}
		
		pip install tensorflow

	\end{verbatim}
		\end{framed}
	This will install the latest stable version of TensorFlow along with necessary dependencies.
	
	\item \textbf{Verify the installation:}  
	After installation, check if TensorFlow is installed correctly by launching Python and importing the library:
	\begin{framed}
	\begin{verbatim}
		python
		>>> import tensorflow as tf
		>>> print(tf.__version__)
	\end{verbatim}
		\end{framed}
	If you see the version number printed without errors, you are good to go!
	
	\item \textbf{GPU Support (Optional):}  
	If your system has compatible NVIDIA GPUs and you want faster training, install the GPU-enabled TensorFlow package:
	\begin{framed}
	\begin{verbatim}
		pip install tensorflow-gpu
	\end{verbatim}
\end{framed}
	Note that this requires installing NVIDIA CUDA and cuDNN drivers, which you can find instructions for at \url{https://www.tensorflow.org/install/gpu}.
	
	\item \textbf{Using Anaconda (Alternative):}  
	If you use the Anaconda Python distribution, you can install TensorFlow easily with:
	\begin{framed}
	\begin{verbatim}
		conda install tensorflow
	\end{verbatim}
\end{framed}
	This automatically manages dependencies for you.
\end{enumerate}




\subsection{Example -- Description}
TensorFlow uses two main execution paradigms:

\begin{itemize}
	\item \textbf{Graph Execution (TensorFlow 1.x):} Users define a static computational graph, then run the graph in a session. This approach optimizes computations but is less intuitive for debugging.
	\item \textbf{Eager Execution (TensorFlow 2.x):} Operations are evaluated immediately as they are called, enabling easier and more interactive model building, similar to standard Python programming.
\end{itemize}

TensorFlow models typically consist of these steps:
\begin{enumerate}
	\item Define the computational graph or model architecture (e.g., layers in a neural network).
	\item Compile the model by specifying optimizer, loss function, and evaluation metrics.
	\item Train the model on data using \texttt{model.fit()}.
	\item Evaluate or predict outcomes on new data using \texttt{model.evaluate()} or \texttt{model.predict()}.
\end{enumerate}

Examples include:
\begin{itemize}
	\item \textbf{Matrix multiplication using tensors:} Performing operations on multidimensional arrays to compute mathematical results efficiently.
	\item \textbf{Building a simple feedforward neural network for regression:} Predicting continuous outputs such as house prices based on input features.
	\item \textbf{Implementing a convolutional neural network (CNN) for image classification:} Identifying objects in images, such as classifying handwritten digits or detecting cats and dogs.
\end{itemize}

\subsection{Example -- Manual}
Basic code examples illustrating key TensorFlow operations:

\begin{verbatim}
	# Example 1: Simple Tensor Operation (Matrix Multiplication)
	import tensorflow as tf
	x = tf.constant([[1.0, 2.0]])
	y = tf.matmul(x, x, transpose_b=True)
	print(y.numpy())
	# Output: [[5.]]
	
	# Example 2: Define a simple sequential model for regression
	model = tf.keras.Sequential([
	tf.keras.layers.Dense(10, activation='relu', input_shape=(5,)),
	tf.keras.layers.Dense(1)
	])
	model.compile(optimizer='adam', loss='mse')
	
	# Example 3: Train the model (assuming X_train, y_train are defined)
	model.fit(X_train, y_train, epochs=5, batch_size=32)
\end{verbatim}

\subsection{Example -- Code}
More detailed examples including evaluation and prediction:

\begin{lstlisting}[language=python, basicstyle=\ttfamily\small]
	# Example 1: Predicting new values using the trained model
	y_pred = model.predict(X_test)
	print(y_pred)
	
	# Example 2: Evaluate the model performance on test data
	loss = model.evaluate(X_test, y_test)
	print(f'Test loss: {loss}')
	
	# Example 3: Using tf.data to create a dataset pipeline for efficient training
	import numpy as np
	dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
	dataset = dataset.shuffle(buffer_size=1024).batch(32)
	
	# Train the model using the dataset pipeline
	model.fit(dataset, epochs=10)
\end{lstlisting}


\subsection{Example -- Files}
TensorFlow allows saving and loading models and datasets for reuse:

\begin{verbatim}
	# Save the entire model to a HDF5 file
	model.save('model.h5')
	
	# Load the model later from HDF5 file
	new_model = tf.keras.models.load_model('model.h5')
	
	# Save model in TensorFlow SavedModel format (recommended for deployment)
	model.save('saved_model_dir')
	
	# Load SavedModel format
	loaded_model = tf.keras.models.load_model('saved_model_dir')
	
	# Working with tf.data datasets:
	# Save dataset as TFRecord files for efficient storage and input
	def _bytes_feature(value):
	return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
	
	# (User-defined code required for TFRecord creation and reading)
\end{verbatim}

Additional use cases include exporting models to TensorFlow Lite for mobile deployment or to TensorFlow.js for web applications.

\subsection{Further Reading}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., ... \& Zheng, X., \textit{TensorFlow: A System for Large-Scale Machine Learning}, Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2016 \cite{abadi2016tensorflow}.


\section{NumPy}

\subsection{Introduction}
NumPy, short for Numerical Python, is a powerful open-source library for numerical computing in Python. It is optimized for performance and serves as the foundation for many scientific and data analysis packages \cite{harris2020array}


\subsection{Description}
As described by Harris et al. \cite{harris2020array}, NumPy introduces the \texttt{ndarray}, a multidimensional array object. Unlike regular Python lists, NumPy arrays support element-wise operations and broadcasting, which enable fast computations over large datasets. NumPy has become widely used across fields such as data science, machine learning, physics, and engineering.


\subsection{Installation}

If you're new to Python or programming, follow these step-by-step instructions to install NumPy correctly on your system.

\begin{enumerate}
	\item \textbf{Check if Python is installed:}
	
	Open your command prompt (Windows) or terminal (Mac/Linux), and type:
	\begin{framed}
		\begin{verbatim}
			python --version
		\end{verbatim}
	\end{framed}
	
	If Python is installed, you'll see something like \texttt{Python 3.10.12}. If not, download and install Python from \url{https://www.python.org/downloads/}, and make sure to check the box \textbf{Add Python to PATH} during installation.
	
	\item \textbf{Ensure pip is installed:}
	
	Pip is Python's package installer. You can check and install it using:
	\begin{framed}
	\begin{verbatim}
		python -m ensurepip --upgrade
	\end{verbatim}
\end{framed}
	This ensures pip is available and up to date.
	
	\item \textbf{Install NumPy using pip:}
	
	Now you're ready to install NumPy:
		\begin{framed}
	\begin{verbatim}
		pip install numpy
	\end{verbatim}
\end{framed}
	This command will download and install the latest version of NumPy from the Python Package Index (PyPI).
	
	\item \textbf{Verify the installation:}
	
	Launch Python in your terminal or shell and run:
		\begin{framed}
	\begin{verbatim}
		python
		>>> import numpy as np
		>>> print(np.__version__)
	\end{verbatim}
\end{framed}
	This should display the installed NumPy version, such as \texttt{1.26.4}, confirming that NumPy is working correctly.
\end{enumerate}

\textbf{Tip:} If you're using Anaconda or Jupyter Notebook, you can also install NumPy using:
\begin{framed}
\begin{verbatim}
	conda install numpy
	
\end{verbatim}
\end{framed}




\subsection{Example - Description}
These examples show what NumPy is commonly used for:

\begin{itemize}
	\item \textbf{Statistical Analysis}: Calculate mean, median, standard deviation.
	\item \textbf{Matrix Operations}: Dot product, matrix multiplication, transpose.
	\item \textbf{Array Manipulations}: Reshaping, stacking, flattening arrays.
\end{itemize}

\subsection{Example - Manual}
Step-by-step breakdowns:

\begin{enumerate}
	\item \textbf{Mean and Standard Deviation}
	\begin{framed}
	\begin{verbatim}
		data = np.array([4, 7, 1, 9])
		mean = np.mean(data)
		std = np.std(data)
	\end{verbatim}
\end{framed}

	
	\item \textbf{2D Array Matrix Multiplication}
	\begin{framed}
	\begin{verbatim}
		A = np.array([[1, 2], [3, 4]])
		B = np.array([[5, 6], [7, 8]])
		result = np.dot(A, B)
	\end{verbatim}
\end{framed}
	
	\item \textbf{Broadcasting Example}
	\begin{framed}
	\begin{verbatim}
		arr = np.array([1, 2, 3])
		print(arr + 5)
	\end{verbatim}
\end{framed}
\end{enumerate}


\subsection{Example - Code}

\begin{lstlisting}[style=pythonstyle,caption={1. Normalize Data}]
	import numpy as np
	data = np.array([10, 20, 30, 40, 50])
	normalized = (data - np.mean(data)) / np.std(data)
	print("Normalized:", normalized)
\end{lstlisting}

\begin{lstlisting}[style=pythonstyle,caption={2. Matrix Multiplication}]
	A = np.array([[1, 2], [3, 4]])
	B = np.array([[2, 0], [1, 2]])
	result = np.dot(A, B)
	print("Dot product:\n", result)
\end{lstlisting}

\begin{lstlisting}[style=pythonstyle,caption={3. Broadcasting Addition}]
	arr = np.array([1, 2, 3])
	added = arr + 10
	print("After adding 10:", added)
\end{lstlisting}

\subsection{Example - Files}

\begin{lstlisting}[style=pythonstyle,caption={1. Save and Load Array}]
	import numpy as np
	arr = np.array([100, 200, 300])
	np.save('saved\_array.npy', arr)
	loaded = np.load('saved\_array.npy')
	print("Loaded array:", loaded)
\end{lstlisting}

\begin{lstlisting}[style=pythonstyle,caption={2. Save and Load Multiple Arrays}]
	np.savez('multiple\_arrays.npz', x=arr, y=arr*2)
	data = np.load('multiple\_arrays.npz')
	print("x:", data['x'], "y:", data['y'])
\end{lstlisting}

\begin{lstlisting}[style=pythonstyle,caption={3. Save as Text File}]
	np.savetxt('data.txt', arr, delimiter=',')
	loaded_text = np.loadtxt('data.txt', delimiter=',')
	print("Text file loaded:", loaded_text)
\end{lstlisting}

\subsection{Further Reading}
\begin{itemize}
	\item Official Documentation: \texttt{https://numpy.org/doc/}
	\item Beginner Tutorials: \texttt{https://numpy.org/learn/}
	\item NumPy Quickstart: \texttt{https://numpy.org/doc/stable/user/quickstart.html}
\end{itemize}



\section{Matplotlib}

\subsection{Introduction}
Matplotlib is the de facto standard library for creating 2D plots and visualizations in Python \cite{hunter2007matplotlib}. It offers a powerful, flexible, and easy-to-use framework for generating a wide variety of static, animated, and interactive plots. Due to its extensive functionality and broad adoption in scientific computing, data analysis, and machine learning communities, Matplotlib is considered essential for visualizing data and conveying insights clearly and effectively.

\subsection{Description}
Matplotlib supports numerous plot types, including but not limited to:

\begin{itemize}
	\item \textbf{Line plots:} Useful for showing trends, continuous data, or time series.
	\item \textbf{Scatter plots:} Ideal for illustrating relationships or correlations between variables.
	\item \textbf{Histograms:} Depict data distribution by grouping values into bins.
	\item \textbf{Bar charts:} Used for categorical comparisons.
	\item \textbf{Pie charts:} Visualize proportions within a whole.
	\item \textbf{Subplots:} Enable multiple plots within a single figure for comparative visualization.
\end{itemize}

Matplotlib also provides fine-grained control over plot elements such as colors, labels, gridlines, legends, fonts, and figure size. Additionally, it supports exporting visualizations to various file formats, including PNG, PDF, SVG, and EPS, making it suitable for publication-quality graphics \cite{hunter2007matplotlib}.

\subsection{Installation}
For users who are new to Python and Matplotlib, the installation process involves a few simple steps:

\begin{enumerate}
	\item \textbf{Ensure Python is installed:} Download and install Python from the official website \url{https://www.python.org/downloads/} if it is not already present on your system.
	
	\item \textbf{Open a command prompt or terminal:}  
	\begin{itemize}
		\item Windows: Press \texttt{Win + R}, type \texttt{cmd}, and press Enter.
		\item Linux/macOS: Open the Terminal application.
	\end{itemize}
	
	\item \textbf{Verify Python installation by typing:}
	\begin{framed}
		\begin{verbatim}
			python --version
		\end{verbatim}
	\end{framed}
	or, on some systems,
	\begin{framed}
		\begin{verbatim}
			python3 --version
		\end{verbatim}
	\end{framed}
	
	\item \textbf{Install Matplotlib using pip:}
	\begin{framed}
		\begin{verbatim}
			pip install matplotlib
		\end{verbatim}
	\end{framed}
	
	\item If you encounter permission issues, try:
	\begin{framed}
		\begin{verbatim}
			pip install --user matplotlib
		\end{verbatim}
	\end{framed}
	
	\item \textbf{Verify the installation by opening Python and importing Matplotlib:}
	\begin{framed}
		\begin{verbatim}
			python
			>>> import matplotlib
			>>> matplotlib.__version__
		\end{verbatim}
	\end{framed}
	
	\item \textbf{If you use the Anaconda distribution, Matplotlib often comes pre-installed. Update it with:}
	\begin{framed}
		\begin{verbatim}
			conda update matplotlib
		\end{verbatim}
	\end{framed}
\end{enumerate}

\subsection{Example -- Description}
Matplotlib offers two primary interfaces for creating plots:

\begin{itemize}
	\item \textbf{Pyplot interface (imperative):} Provides a MATLAB-like, stateful interface suitable for quick and simple plotting commands.
	\item \textbf{Object-oriented interface:} Uses Figure and Axes objects to build plots, allowing for greater control and customization, especially for complex figures or multiple subplots.
\end{itemize}

Both approaches can be used interchangeably, depending on the complexity of the visualization and user preference.

\subsection{Example -- Manual}
A straightforward example using the Pyplot interface to create a simple line plot, add a title, save it as an image file, and display it is shown below:

\begin{framed}
	\begin{verbatim}
		import matplotlib.pyplot as plt
		
		# Define data points
		x = [1, 2, 3]
		y = [4, 5, 6]
		
		# Create a line plot
		plt.plot(x, y)
		
		# Add a title to the plot
		plt.title('Example Plot')
		
		# Save the figure as a PNG image
		plt.savefig('fig.png')
		
		# Display the plot
		plt.show()
	\end{verbatim}
\end{framed}

\subsection{Example -- Code}
Below are several examples demonstrating different plot types using the object-oriented approach for better customization:

\begin{framed}
	\begin{verbatim}
		import matplotlib.pyplot as plt
		
		# Histogram Example
		data = [12, 15, 13, 17, 19, 14, 16, 18, 20, 13, 15, 16]
		fig, ax = plt.subplots()
		ax.hist(data, bins=20, color='skyblue')
		ax.set_xlabel('Value')
		ax.set_ylabel('Frequency')
		ax.set_title('Histogram Example')
		plt.show()
		
		# Scatter Plot Example
		fig, ax = plt.subplots()
		x = [5, 7, 8, 7, 2, 17, 2, 9]
		y = [99, 86, 87, 88, 100, 86, 103, 87]
		ax.scatter(x, y, color='red')
		ax.set_title('Scatter Plot Example')
		plt.show()
		
		# Bar Chart Example
		fig, ax = plt.subplots()
		categories = ['A', 'B', 'C']
		values = [10, 20, 15]
		ax.bar(categories, values, color='green')
		ax.set_title('Bar Chart Example')
		plt.show()
	\end{verbatim}
\end{framed}


\subsection{Example -- Files}
Matplotlib plots can be embedded directly within interactive environments such as Jupyter notebooks for inline visualization, making data exploration intuitive and dynamic. Additionally, plots can be saved to external files using the \texttt{plt.savefig()} function. Supported file formats include:

\begin{itemize}
	\item \textbf{PNG} — Portable Network Graphics, suitable for web and general use.
	\item \textbf{PDF} — Portable Document Format, preferred for high-quality print and documentation.
	\item \textbf{SVG} — Scalable Vector Graphics, ideal for scalable, lossless images in web or graphic design.
\end{itemize}

To save a figure as a PDF file, use:

\begin{framed}
	\begin{verbatim}
		plt.savefig('plot.pdf')
	\end{verbatim}
\end{framed}

This flexibility allows seamless integration of plots into reports, presentations, and publications.

\subsection{Further Reading}
Hunter, J. D., \textit{matplotlib – A Portable Python Plotting Package}, Computing in Science \& Engineering, 9(3), 90–95 (2007) \cite{hunter2007matplotlib}.


\section{Scikit-learn}

\subsection{Introduction}
Scikit-learn is a widely used, user-friendly Python library that provides a comprehensive suite of machine learning algorithms and tools \cite{pedregosa2011scikitlearn}. It is designed for efficient and accessible application of machine learning techniques such as classification, regression, clustering, and dimensionality reduction. Scikit-learn emphasizes ease of use and consistent API design, making it an essential tool for both beginners and experienced practitioners in data science and artificial intelligence.

\subsection{Description}
Scikit-learn offers a broad array of machine learning functionalities, including:

\begin{itemize}
	\item \textbf{Classification:} Algorithms such as Logistic Regression, Support Vector Machines (SVM), Decision Trees, and Random Forests used for categorizing data into predefined classes.
	\item \textbf{Regression:} Models including Linear Regression, Ridge Regression, and Gradient Boosting for predicting continuous outcomes.
	\item \textbf{Clustering:} Techniques like K-Means, DBSCAN, and Agglomerative Clustering for grouping data without labeled outcomes.
	\item \textbf{Dimensionality Reduction:} Methods such as Principal Component Analysis (PCA) and t-SNE to reduce feature space while preserving important information.
	\item \textbf{Model Selection and Evaluation:} Tools for hyperparameter tuning, cross-validation, and performance metrics to optimize and assess models.
\end{itemize}

All these algorithms share a consistent, easy-to-learn interface with core methods like \texttt{fit()}, \texttt{predict()}, and \texttt{score()}, facilitating smooth workflows from training to evaluation \cite{pedregosa2011scikitlearn}.

\subsection{Installation}
For users new to Python or machine learning, follow these clear step-by-step instructions to install scikit-learn:

\begin{enumerate}
	\item \textbf{Verify Python installation:}  
	Make sure Python 3.6 or later is installed on your computer. You can download it from \url{https://www.python.org/downloads/} if it’s not already installed.
	
	\item \textbf{Open your command prompt or terminal:}
	\begin{itemize}
		\item \textbf{Windows:} Press \texttt{Win + R}, type \texttt{cmd}, and press Enter.
		\item \textbf{Linux/macOS:} Open the Terminal application.
	\end{itemize}
	
	\item \textbf{Check your Python version:}  
	Run the following command to confirm your Python version:
	\begin{framed}
		\begin{verbatim}
			python --version
		\end{verbatim}
	\end{framed}
	This helps ensure compatibility with scikit-learn.
	
	\item \textbf{(Recommended) Create a virtual environment:}  
	To avoid package conflicts, create and activate a virtual environment:
	\begin{framed}
		\begin{verbatim}
			python -m venv sklearn-env
		\end{verbatim}
	\end{framed}
	Activate it by running:
	\begin{itemize}
		\item Windows:
		\begin{framed}
			\begin{verbatim}
				sklearn-env\Scripts\activate
			\end{verbatim}
		\end{framed}
		\item macOS/Linux:
		\begin{framed}
			\begin{verbatim}
				source sklearn-env/bin/activate
			\end{verbatim}
		\end{framed}
	\end{itemize}
	
	\item \textbf{Install scikit-learn using pip:}  
	Once your environment is ready, install scikit-learn by running:
	\begin{framed}
		\begin{verbatim}
			pip install scikit-learn
		\end{verbatim}
	\end{framed}
	
	\item \textbf{Handling permission errors:}  
	If you encounter permission errors, try installing with the \texttt{--user} flag:
	\begin{framed}
		\begin{verbatim}
			pip install --user scikit-learn
		\end{verbatim}
	\end{framed}
	
	\item \textbf{Verify the installation:}  
	Open Python and import scikit-learn to check that it installed correctly:
	\begin{framed}
		\begin{verbatim}
			python
			>>> import sklearn
			>>> print(sklearn.__version__)
		\end{verbatim}
	\end{framed}
	
	\item \textbf{Using Anaconda (alternative method):}  
	If you are using the Anaconda distribution, scikit-learn is often pre-installed. To update or install it, use:
	\begin{framed}
		\begin{verbatim}
			conda install scikit-learn
		\end{verbatim}
	\end{framed}
	or
	\begin{framed}
		\begin{verbatim}
			conda update scikit-learn
		\end{verbatim}
	\end{framed}
	You can learn more about Anaconda at \url{https://www.anaconda.com/products/distribution}.
\end{enumerate}

\subsection{Example -- Description}
Scikit-learn follows a straightforward approach to model training and prediction:

\begin{itemize}
	\item \texttt{fit(X, y)} is used to train the model on the input features \texttt{X} and target values \texttt{y}.
	\item \texttt{predict(X)} applies the trained model to new input data \texttt{X} to generate predictions.
	\item \texttt{score(X, y)} evaluates the model’s performance on test data.
\end{itemize}

This uniform API allows easy switching between different algorithms with minimal code changes.

Examples include:

\begin{itemize}
	\item \textbf{Classification:} Train a Support Vector Machine to classify handwritten digits.
	\item \textbf{Regression:} Fit a Ridge Regression model to predict housing prices.
	\item \textbf{Clustering:} Apply K-Means clustering to group customers based on purchasing behavior.
\end{itemize}

\subsection{Example -- Manual}
Basic examples for model training in different tasks:

\begin{framed}
	\begin{verbatim}
		# Linear Regression (Regression task)
		from sklearn.linear_model import LinearRegression
		model = LinearRegression()
		model.fit(X_train, y_train)
		
		# Logistic Regression (Classification task)
		from sklearn.linear_model import LogisticRegression
		model = LogisticRegression()
		model.fit(X_train, y_train)
		
		# K-Means Clustering (Unsupervised task)
		from sklearn.cluster import KMeans
		model = KMeans(n_clusters=3)
		model.fit(X_train)
	\end{verbatim}
\end{framed}

\subsection{Example -- Code}
Generating predictions and evaluating model performance for different scenarios:


	\begin{verbatim}
		from sklearn.metrics import mean_squared_error, accuracy_score
		
		# Regression: Mean Squared Error (MSE)
		y_pred = model.predict(X_test)
		mse = mean_squared_error(y_test, y_pred)
		print(f'Mean Squared Error: {mse}')
		
		# Classification: Accuracy Score
		y_pred = model.predict(X_test)
		accuracy = accuracy_score(y_test, y_pred)
		print(f'Accuracy: {accuracy}')
		
		# Clustering: Compute silhouette score to evaluate clustering quality
		from sklearn.metrics import silhouette_score
		labels = model.labels_
		score = silhouette_score(X_test, labels)
		print(f'Silhouette Score: {score}')
	\end{verbatim}


\subsection{Example -- Files}
Saving and loading models to disk for reuse and deployment:

\begin{framed}
	\begin{verbatim}
		import joblib
		
		# Save the trained model to a file
		joblib.dump(model, 'model.pkl')
		
		# Load the model from the file
		model = joblib.load('model.pkl')
	\end{verbatim}
\end{framed}

Additional examples:

\begin{framed}
	\begin{lstlisting}[language=python, basicstyle=\ttfamily\small]
		# Save multiple models
		joblib.dump({'regressor': model_reg, 'classifier': model_clf}, 'models.pkl')
		
		# Load multiple models
		models = joblib.load('models.pkl')
		model_reg = models['regressor']
		model_clf = models['classifier']
	\end{lstlisting}
\end{framed}



\subsection{Further Reading}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... \& Duchesnay, É., \textit{Scikit-learn: Machine Learning in Python}, Journal of Machine Learning Research, 12, 2825-2830 (2011) \cite{pedregosa2011scikitlearn}.
